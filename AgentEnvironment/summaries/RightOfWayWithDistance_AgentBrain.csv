Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
6010000,1.9450601,7.4927025,134.08333333333334,61.59311156526868,61.59311156526868,0.0
6020000,1.6939058,7.714389,195.8235294117647,61.145024654415465,61.145024654415465,0.0
6030000,2.1490476,5.135138,237.0,60.48421082239737,60.48421082239737,0.0
6040000,2.2715285,2.4881618,694.0,57.12357974759652,57.12357974759652,0.0
6050000,1.9029617,7.9480176,172.125,60.525508885220916,60.525508885220916,0.0
6060000,2.6224465,3.0931907,228.0,60.41480039199814,60.41480039199814,0.0
6070000,2.0932271,5.2546306,400.0,60.79287059130147,60.79287059130147,0.0
6080000,1.8023258,5.4030766,279.0,60.13371190661241,60.13371190661241,0.0
6090000,2.3668664,4.742231,245.25,59.65218713632203,59.65218713632203,0.0
6100000,2.0396378,6.6443863,180.1764705882353,61.79637191084433,61.79637191084433,0.0
6110000,2.649529,4.2380943,310.25,61.167534628177236,61.167534628177236,0.0
6120000,2.4251196,2.528967,527.5,55.70959581097122,55.70959581097122,0.0
