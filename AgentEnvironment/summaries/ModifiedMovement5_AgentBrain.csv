Steps,Policy/Extrinsic Value Estimate,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Entropy,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
130000,-2.0472722,0.047068276,0.02854287,0.00029399683,4.4262657,999.5,-43.37233195306726,-43.37233195306726,1.0
140000,-2.274551,0.06453842,0.023345288,0.00029346888,4.4108715,None,None,None,1.0
150000,-2.4660401,0.032841865,0.020838585,0.00029291847,4.3926053,None,None,None,1.0
160000,-2.6569493,0.038470116,0.028536921,0.00029238084,4.389247,None,None,None,1.0
170000,-2.9027321,0.020710621,0.02511734,0.00029183048,4.3918223,None,None,None,1.0
180000,-3.0799809,0.027745405,0.033239234,0.00029128007,4.3640337,None,None,None,1.0
190000,-3.1965842,0.013370403,0.016973734,0.0002907424,4.3611536,None,None,None,1.0
200000,-3.3759084,0.023684928,0.019919522,0.00029019202,4.354774,None,None,None,1.0
210000,-3.5704389,0.021028161,0.020987226,0.0002896416,4.341157,None,None,None,1.0
220000,-3.7177234,0.02299026,0.027452208,0.000289104,4.3170958,None,None,None,1.0
230000,-3.8650274,0.012738922,0.02323485,0.0002885536,4.301133,None,None,None,1.0
240000,-3.9691546,0.012122778,0.025983064,0.00028800318,4.2724247,None,None,None,1.0
250000,-4.092911,None,None,None,4.264603,None,None,None,1.0
260000,-3.800616,0.011469102,0.026835524,0.00028746566,4.2721853,1999.0,-82.42435127310455,-82.42435127310455,1.0
270000,-3.33346,0.07013697,0.025178155,0.00028692803,4.2683544,None,None,None,1.0
280000,-3.6122139,0.019674335,0.018302001,0.00028639042,4.2530007,None,None,None,1.0
290000,-3.6861067,0.016389094,0.030373085,0.00028584,4.2558107,None,None,None,1.0
300000,-3.8650575,0.01988462,0.02227195,0.00028528963,4.2443953,None,None,None,1.0
310000,-3.9060144,0.018617122,0.018607246,0.000284752,4.234096,None,None,None,1.0
