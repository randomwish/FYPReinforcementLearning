Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
20000,-0.21315892,2.195574,0.53587765,0.024149694,0.00029841607,999.0,-49.93333035310109,-49.93333035310109,1.0
30000,-0.5555971,2.196299,0.34018233,0.020708935,0.00029674202,999.0,-49.857139876910615,-49.857139876910615,1.0
40000,-0.89905787,2.1930828,0.29379013,0.02666534,0.00029506805,None,-49.99999701976776,-49.99999701976776,1.0
50000,-1.0940101,2.1894665,0.23948812,0.017961407,0.00029348402,999.0,-49.93333035310109,-49.93333035310109,1.0
60000,-1.2040255,2.1945896,0.3486061,0.018394312,0.00029181005,999.0,-49.92856844833919,-49.92856844833919,1.0
70000,-1.5919603,2.1884835,0.31968,0.027655846,0.000290136,None,-49.99999701976776,-49.99999701976776,1.0
80000,-1.8107264,2.1822507,0.21367049,0.025104532,0.00028859882,939.5,-46.27437220513821,-46.27437220513821,1.0
