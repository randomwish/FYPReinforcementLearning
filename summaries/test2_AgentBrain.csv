Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
40000,-0.006888826,1.4152787,0.000528301,0.02313236,0.00029688966,1999.0,0.05555555555555555,0.05555555555555555,1.0
50000,-0.015188492,1.4120038,0.00049080345,0.01713476,0.00029582405,None,None,None,1.0
60000,-0.014130177,1.410137,0.00012018159,0.021911263,0.0002947872,None,None,None,1.0
70000,-0.014154656,1.4112027,7.7544624e-05,0.023990072,0.00029375037,None,None,None,1.0
80000,0.012680079,1.411731,6.9968235e-05,0.021581728,0.00029268482,1999.0,0.0,0.0,1.0
90000,0.0057334066,1.4136176,0.00013826089,0.022403121,0.00029164803,None,None,None,1.0
100000,0.009176689,1.4150658,1.9124225e-05,0.022250032,0.00029061118,None,None,None,1.0
110000,0.013177958,1.4139495,1.9157531e-05,0.01960093,0.00028957438,1999.0,0.0,0.0,1.0
120000,0.0079508,1.4136996,0.00040789906,0.02412788,0.00028850883,None,None,None,1.0
130000,0.00440001,1.4149748,1.3027395e-05,0.027670546,0.00028747198,None,None,None,1.0
140000,0.004669861,1.4156257,7.716754e-06,0.02369764,0.00028643518,None,None,None,1.0
150000,0.009800507,1.4160856,0.0006422259,0.020397084,0.00028536964,1999.0,0.05555555555555555,0.05555555555555555,1.0
160000,0.00019692573,1.4164965,0.00015558269,0.018148264,0.0002843328,None,None,None,1.0
170000,-0.0024143115,1.4157063,1.8202829e-05,0.019846585,0.00028329607,None,None,None,1.0
180000,-0.003100842,1.414152,7.813501e-06,0.021090977,0.00028225925,1999.0,0.058823529411764705,0.058823529411764705,1.0
